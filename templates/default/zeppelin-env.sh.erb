#export ZEPPELIN_PORT=<%= node.zeppelin.port %>
export ZEPPELIN_NOTEBOOK_DIR=notebook
export ZEPPELIN_INTERPRETERS=spark:com.nflabs.zeppelin.spark.SparkInterpreter,sql:com.nflabs.zeppelin.spark.SparkSqlInterpreter,md:com.nflabs.zeppelin.markdown.Markdown,sh:com.nflabs.zeppelin.shell.ShellInterpreter,org.apache.zeppelin.flink.FlinkInterpreter
export ZEPPELIN_INTERPRETER_DIR=interpreter
export MASTER=yarn-client
export ZEPPELIN_JAVA_OPTS=""
export HADOOP_CONF_DIR=<%= @hadoop_dir %>/etc/hadoop

# export ZEPPELIN_JAVA_OPTS      		# Additional jvm options. for example, export ZEPPELIN_JAVA_OPTS="-Dspark.executor.memory=8g -Dspark.cores.max=16"
# export ZEPPELIN_MEM            		# Zeppelin jvm mem options Default -Xmx1024m -XX:MaxPermSize=512m
# export ZEPPELIN_INTP_MEM       		# zeppelin interpreter process jvm mem options. Default = ZEPPELIN_MEM
# export ZEPPELIN_INTP_JAVA_OPTS 		# zeppelin interpreter process jvm options. Default = ZEPPELIN_JAVA_OPTS

# export ZEPPELIN_LOG_DIR        		# Where log files are stored.  PWD by default.
# export ZEPPELIN_PID_DIR        		# The pid files are stored. /tmp by default.
# export ZEPPELIN_NOTEBOOK_DIR   		# Where notebook saved
# export ZEPPELIN_NOTEBOOK_HOMESCREEN		# Id of notebook to be displayed in homescreen. ex) 2A94M5J1Z
# export ZEPPELIN_NOTEBOOK_HOMESCREEN_HIDE	# hide homescreen notebook from list when this value set to "true". default "false"
# export ZEPPELIN_NOTEBOOK_S3_BUCKET    # Bucket where notebook saved
# export ZEPPELIN_NOTEBOOK_S3_USER      # User in bucket where notebook saved. For example bucket/user/notebook/2A94M5J1Z/note.json
# export ZEPPELIN_IDENT_STRING   		# A string representing this instance of zeppelin. $USER by default.
# export ZEPPELIN_NICENESS       		# The scheduling priority for daemons. Defaults to 0.


#### Spark interpreter configuration ####

## Use provided spark installation ##
## defining SPARK_HOME makes Zeppelin run spark interpreter process using spark-submit
export SPARK_HOME=<%= @spark_dir %>
export HADOOP_HOME=<%= @hadoop_dir %>
#export SPARK_SUBMIT_OPTIONS # (optional) extra options to pass to spark submit. eg) "--driver-memory 512M --executor-memory 1G".

## Use embedded spark binaries ##
## without SPARK_HOME defined, Zeppelin still able to run spark interpreter process using embedded spark binaries.
## however, it is not encouraged when you can define SPARK_HOME
##
# Options read in YARN client mode
# export HADOOP_CONF_DIR=/srv/hadoop-2.4.0/etc/hadoop	# yarn-site.xml is located in configuration directory in HADOOP_CONF_DIR.
# Pyspark (supported with Spark 1.2.1 and above)
# To configure pyspark, you need to set spark distribution's path to 'spark.home' property in Interpreter setting screen in Zeppelin GUI
# export PYSPARK_PYTHON          		# path to the python command. must be the same path on the driver(Zeppelin) and all workers.
# export PYTHONPATH  

## Spark interpreter options ##
##
# export ZEPPELIN_SPARK_USEHIVECONTEXT=false  # Use HiveContext instead of SQLContext if set true. true by default.
# export ZEPPELIN_SPARK_CONCURRENTSQL   # Execute multiple SQL concurrently if set true. false by default.
# export ZEPPELIN_SPARK_MAXRESULT       # Max number of SparkSQL result to display. 1000 by default.

## Zeppelin SSL Config
export ZEPPELIN_SSL=<%= @sslenabled %>
export ZEPPELIN_SSL_CLIENT_AUTH=<%= @sslclientauth %>
export ZEPPELIN_SSL_KEYSTORE_PATH=<%= @sslkeystorepath %>
export ZEPPELIN_SSL_KEYSTORE_TYPE=<%= @sslkeystoretype %>
export ZEPPELIN_SSL_KEYSTORE_PASSWORD=<%= @sslkeystorepassword %>
export ZEPPELIN_SSL_TRUSTSTORE_PATH=<%= @ssltruststorepath %>
export ZEPPELIN_SSL_TRUSTSTORE_TYPE=<% @ssltruststoretype %>
export ZEPPELIN_SSL_TRUSTSTORE_PASSWORD=<%= @ssltruststorepassword %>	